# TransE: Translating Embeddings for Modeling Multi-relational Data

## Implementaci√≥n Fiel del Paper Original (Bordes et al., 2013)

Esta implementaci√≥n sigue meticulosamente el paper original "Translating Embeddings for Modeling Multi-relational Data" publicado en NIPS 2013.

---

## üìö Relaci√≥n con el Paper

### 1. Fundamento Te√≥rico (Secci√≥n 2 del Paper)

**Idea Central:**
```
Si existe la relaci√≥n (head, label, tail), entonces:
    h + r ‚âà t
```

Donde:
- `h`: Embedding de la entidad head
- `r`: Embedding de la relaci√≥n
- `t`: Embedding de la entidad tail

**Intuici√≥n Geom√©trica:**
Las relaciones son traslaciones en el espacio de embeddings. Por ejemplo:
- `Paris + capital_of ‚âà France`
- `Entity + hypernym ‚âà Parent_Entity`

### 2. Funci√≥n de Energ√≠a

**Paper (P√°gina 3):**
```
d(h, r, t) = ||h + r - t||_p
```

Donde `p` puede ser:
- `p=1` (norma L1): Distancia Manhattan
- `p=2` (norma L2): Distancia Euclidiana

**Implementaci√≥n:**
```python
def score_triples(self, heads, relations, tails):
    h_emb, r_emb, t_emb = self.get_embeddings(heads, relations, tails)
    translation = h_emb + r_emb - t_emb
    distance = torch.norm(translation, p=self.norm_order, dim=1)
    return -distance  # Negativo porque menor distancia = mejor
```

### 3. Loss Function - Margin-based Ranking (Ecuaci√≥n 1)

**Paper:**
```
L = Œ£_(h,r,t)‚ààS Œ£_(h',r,t')‚ààS' [Œ≥ + d(h,r,t) - d(h',r,t')]_+
```

Donde:
- `[x]_+ = max(0, x)`: Parte positiva
- `Œ≥`: Margen (hiperpar√°metro)
- `S`: Conjunto de tripletas verdaderas
- `S'`: Conjunto de tripletas corruptas

**Implementaci√≥n:**
```python
def forward(self, pos_heads, pos_rels, pos_tails, neg_heads, neg_rels, neg_tails):
    pos_scores = self.score_triples(pos_heads, pos_rels, pos_tails)
    neg_scores = self.score_triples(neg_heads, neg_rels, neg_tails)
    loss = torch.relu(self.margin - pos_scores + neg_scores).mean()
    return loss
```

### 4. Negative Sampling (Ecuaci√≥n 2)

**Paper:**
```
S'_(h,r,t) = {(h', r, t) | h' ‚àà E} ‚à™ {(h, r, t') | t' ‚àà E}
```

Estrategia:
- Para cada tripleta positiva, generar UNA tripleta corrupta
- Corromper SOLO el head O el tail (no ambos)
- Selecci√≥n aleatoria entre corromper head o tail

**Implementaci√≥n:**
```python
def corrupt_batch(pos_triples, num_entities, device):
    neg_triples = pos_triples.clone()
    corrupt_head_mask = torch.rand(batch_size, device=device) < 0.5
    random_entities = torch.randint(0, num_entities, (batch_size,), device=device)
    neg_triples[corrupt_head_mask, 0] = random_entities[corrupt_head_mask]
    neg_triples[~corrupt_head_mask, 2] = random_entities[~corrupt_head_mask]
    return neg_triples
```

### 5. Algoritmo de Entrenamiento (Algoritmo 1)

**Paper - Pasos Clave:**

1. **Inicializaci√≥n (L√≠neas 1-3):**
   ```
   - Relaciones: uniform(-‚àö(6/k), ‚àö(6/k))
   - Entidades: uniform(-‚àö(6/k), ‚àö(6/k))
   ```
   Usa la inicializaci√≥n de Glorot & Bengio (2010) - referencia [4]

2. **Normalizaci√≥n de Relaciones (L√≠nea 2):**
   ```
   r ‚Üê r/||r|| para cada relaci√≥n r
   ```
   ‚ö†Ô∏è SOLO en inicializaci√≥n, NO durante entrenamiento

3. **Loop Principal (L√≠neas 4-13):**
   ```
   Para cada √©poca:
       a) Normalizar entidades: e ‚Üê e/||e|| (L√≠nea 5)
       b) Samplear minibatch (L√≠nea 6)
       c) Generar negativos (L√≠nea 9)
       d) Actualizar con SGD (L√≠nea 12)
   ```

**Implementaci√≥n:**
```python
def train_transe(model, train_data, ...):
    for epoch in range(num_epochs):
        # (a) Normalizar entidades ANTES del batch
        model.normalize_entity_embeddings()
        
        for pos_batch in train_loader:
            # (b) Batch ya viene del loader
            # (c) Generar negativos
            neg_batch = corrupt_batch(pos_batch, num_entities, device)
            
            # (d) Forward + Backward
            loss = model(pos_h, pos_r, pos_t, neg_h, neg_r, neg_t)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
```

### 6. Restricciones de Normalizaci√≥n

**¬øPor qu√© normalizar?**

Del paper (P√°gina 3):
> "This constraint is important for our model, as it is for previous embedding-based 
> methods, because it prevents the training process to trivially minimize L by 
> artificially increasing entity embeddings norms."

Sin normalizaci√≥n, el modelo podr√≠a hacer trampa:
- Aumentar infinitamente las normas de los embeddings
- La loss disminuir√≠a artificialmente sin aprender nada √∫til

**Restricciones:**
- ‚úÖ Entidades: ||e|| = 1 (normalizar CADA √©poca)
- ‚ùå Relaciones: SIN restricci√≥n despu√©s de inicializaci√≥n

**Implementaci√≥n:**
```python
def normalize_entity_embeddings(self):
    with torch.no_grad():
        self.entity_embeddings.weight.data = nn.functional.normalize(
            self.entity_embeddings.weight.data, p=2, dim=1
        )
```

---

## üîß Hiperpar√°metros del Paper

### Tabla de Configuraciones √ìptimas (Secci√≥n 4.2)

| Dataset | k (dim) | Œª (lr) | Œ≥ (margin) | d (norm) |
|---------|---------|--------|------------|----------|
| WN      | 20      | 0.01   | 2          | L1       |
| FB15k   | 50      | 0.01   | 1          | L1       |
| FB1M    | 50      | 0.01   | 1          | L2       |

### B√∫squeda de Hiperpar√°metros

Del paper:
> "We selected the learning rate Œª among {0.001, 0.01, 0.1}, the margin Œ≥ 
> among {1, 2, 10} and the latent dimension k among {20, 50} on the 
> validation set of each data set."

**Implementaci√≥n:**
```python
EMBEDDING_DIM = 50      # k ‚àà {20, 50}
LEARNING_RATE = 0.01    # Œª ‚àà {0.001, 0.01, 0.1}
MARGIN = 1.0            # Œ≥ ‚àà {1, 2, 10}
NORM_ORDER = 1          # L1 o L2
```

---

## üéØ Protocolo de Evaluaci√≥n

### 1. Link Prediction (Secci√≥n 4.2)

**Procedimiento del Paper:**

Para cada tripleta de test `(h, r, t)`:

1. **Corromper Head:**
   - Reemplazar `h` con cada entidad del vocabulario
   - Calcular `d(h', r, t)` para todas las entidades `h'`
   - Rankear por distancia ascendente
   - Guardar el rank de la entidad correcta

2. **Corromper Tail:**
   - Reemplazar `t` con cada entidad del vocabulario
   - Calcular `d(h, r, t')` para todas las entidades `t'`
   - Rankear por distancia ascendente
   - Guardar el rank de la entidad correcta

3. **M√©tricas:**
   - **Mean Rank (MR):** Promedio de los ranks
   - **Mean Reciprocal Rank (MRR):** Promedio de 1/rank
   - **Hits@K:** % de ranks ‚â§ K

**Filtered vs Raw (del Paper):**
> "We propose to remove from the list of corrupted triplets all the triplets 
> that appear either in the training, validation or test set (except the test 
> triplet of interest). This ensures that all corrupted triplets do not belong 
> to the data set."

- **Raw:** Todos los corruptos se consideran (puede ser injusto)
- **Filtered:** Remover tripletas que aparecen en train/valid/test

### 2. Triple Classification

**Protocolo (usado en evaluaci√≥n):**

1. **Generar Negativos:**
   - Para cada tripleta positiva en test, generar 1 negativo
   - Corromper aleatoriamente head o tail

2. **Encontrar Umbral √ìptimo:**
   - Usar conjunto de validaci√≥n
   - Probar diferentes umbrales
   - Seleccionar el que maximiza accuracy

3. **Evaluar en Test:**
   - Aplicar umbral √≥ptimo
   - Calcular: Accuracy, F1, Precision, Recall, AUC-ROC

---

## üö® Manejo de Escenarios Desafiantes

### 1. Out-Of-Knowledge-Base (OOKB)

**Problema:**
En escenarios OOKB, el test contiene entidades que NUNCA aparecieron en train.

**Soluci√≥n Implementada:**
```python
# Crear un embedding especial para entidades desconocidas
self.unknown_entity_embedding = nn.Parameter(
    torch.randn(embedding_dim) * init_bound
)

# Durante inferencia, detectar y manejar entidades OOKB
def get_embeddings(self, heads, relations, tails, handle_ookb=True):
    if handle_ookb:
        ookb_mask_h = heads >= self.num_entities
        ookb_mask_t = tails >= self.num_entities
        
        # Reemplazar con embedding especial
        h_emb[ookb_mask_h] = self.unknown_entity_embedding
        t_emb[ookb_mask_t] = self.unknown_entity_embedding
```

**Justificaci√≥n:**
El paper original NO cubre OOKB. Esta es una extensi√≥n necesaria para:
- Evitar crashes por √≠ndices fuera de rango
- Proporcionar baseline medible (aunque sub√≥ptimo)
- Permitir comparaci√≥n con m√©todos inductivos modernos

### 2. Inductive Learning (Nuevas Relaciones)

**Del Paper (Secci√≥n 4.4):**

Experimento: "Learning to predict new relationships with few examples"
- 40 relaciones desconocidas
- Evaluar con 0, 10, 100, 1000 ejemplos

Resultado:
> "TransE is the fastest method to learn: with only 10 examples of a new 
> relationship, the hits@10 is already 18%"

**Implementaci√≥n:**
Soportado por el DataLoader en modo `'inductive'`.

---

## üìä Resultados Esperados (del Paper)

### Tabla 3: Link Prediction Results

**FB15k (Filtered):**

| Modelo          | Mean Rank | Hits@10 (%) |
|-----------------|-----------|-------------|
| Unstructured    | 979       | 6.3         |
| SE              | 162       | 39.8        |
| SME(Linear)     | 154       | 40.8        |
| **TransE**      | **125**   | **47.1**    |

**WN (Filtered):**

| Modelo          | Mean Rank | Hits@10 (%) |
|-----------------|-----------|-------------|
| Unstructured    | 304       | 38.2        |
| LFM             | 456       | 81.6        |
| **TransE**      | **251**   | **89.2**    |

### An√°lisis por Categor√≠a de Relaci√≥n (Tabla 4)

TransE destaca en:
- ‚úÖ **1-to-Many (tail):** 65.7% Hits@10
- ‚úÖ **Many-to-1 (tail):** 66.7% Hits@10
- ‚úÖ **1-to-1:** 43.7% Hits@10
- ‚ö†Ô∏è **Many-to-Many:** 47.2% / 50.0%

---

## üéì Diferencias Clave vs Otros Modelos

### vs Structured Embeddings (SE)

Del paper (P√°gina 4):
> "SE is more expressive than our proposal. However, its complexity may make 
> it quite hard to learn, resulting in worse performance."

**SE:** Aprende 2 matrices por relaci√≥n ‚Üí M√°s par√°metros ‚Üí M√°s dif√≠cil optimizar
**TransE:** Aprende 1 vector por relaci√≥n ‚Üí Menos par√°metros ‚Üí M√°s f√°cil optimizar

### vs Neural Tensor Network

Del paper (Ecuaci√≥n 3, P√°gina 4):
> "TransE corresponds to the model where L is the identity matrix"

**TransE es un caso especial simplificado:**
- Menos par√°metros (m√°s eficiente)
- Entrenamiento m√°s estable
- Rendimiento competitivo en KBs grandes

---

## üíæ Uso del Script

### Ejecuci√≥n B√°sica

```bash
python transe_model.py
```

### Configuraci√≥n de Par√°metros

Editar en `main()`:

```python
# Dataset
DATASET_NAME = 'CoDEx-M'  # 'FB15k-237', 'WN18RR', etc.
MODE = 'ookb'             # 'standard', 'ookb', 'inductive'

# Hiperpar√°metros (seg√∫n el paper)
EMBEDDING_DIM = 50
LEARNING_RATE = 0.01
MARGIN = 1.0
NORM_ORDER = 1  # 1=L1, 2=L2
```

### Salidas

1. **Durante entrenamiento:**
   - Loss por √©poca
   - MRR en validaci√≥n (para early stopping)

2. **Evaluaci√≥n final:**
   - Ranking: MRR, MR, Hits@1/3/10
   - Clasificaci√≥n: AUC, Accuracy, F1

3. **Reporte PDF:**
   - Gr√°ficas ROC y Precision-Recall
   - Distribuciones de scores
   - An√°lisis de ranking
   - Tabla de m√©tricas

---

## üî¨ Consideraciones T√©cnicas

### 1. Complejidad Computacional

**Par√°metros Totales:**
```
O(n_e * k + n_r * k)
```
Donde:
- `n_e`: N√∫mero de entidades
- `n_r`: N√∫mero de relaciones
- `k`: Dimensi√≥n de embeddings

**Comparaci√≥n (FB15k, Tabla 1):**
- RESCAL: 87.80M par√°metros
- SE: 7.47M par√°metros
- **TransE: 0.81M par√°metros** ‚úÖ

### 2. Limitaciones del Modelo

Del paper (Secci√≥n 3):
> "The simple formulation of TransE... involves drawbacks. For modeling data 
> where 3-way dependencies between h, l and t are crucial, our model can fail."

**Ejemplo problem√°tico:** Kinships dataset
- Requiere interacciones ternarias complejas
- TransE no alcanza state-of-the-art

**Fortalezas:**
- KBs grandes y heterog√©neos (Freebase, WordNet)
- Relaciones jer√°rquicas (hypernym, part-of)
- Relaciones 1-to-1 (capital-of)

### 3. Optimizaci√≥n

**SGD con Learning Rate Constante:**
Del paper:
> "The parameters are then updated by taking a gradient step with constant 
> learning rate."

No usa:
- ‚ùå Learning rate decay
- ‚ùå Momentum
- ‚ùå Adam/AdaGrad

Solo usa:
- ‚úÖ SGD vanilla
- ‚úÖ Early stopping en validaci√≥n

---

## üìñ Referencias

```bibtex
@inproceedings{bordes2013translating,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto 
          and Weston, Jason and Yakhnenko, Oksana},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2787--2795},
  year={2013}
}
```

---

## ‚úÖ Checklist de Fidelidad al Paper

- [x] Inicializaci√≥n Glorot uniforme (l√≠neas 1-3, Algoritmo 1)
- [x] Normalizaci√≥n de relaciones solo en init (l√≠nea 2)
- [x] Normalizaci√≥n de entidades cada √©poca (l√≠nea 5)
- [x] Negative sampling (Ecuaci√≥n 2)
- [x] Margin ranking loss (Ecuaci√≥n 1)
- [x] SGD con learning rate constante
- [x] Early stopping en validaci√≥n
- [x] Evaluaci√≥n filtered y raw
- [x] Link prediction protocol
- [x] Hiperpar√°metros del paper
- [x] Manejo de OOKB (extensi√≥n)

---

## üöÄ Mejoras Futuras (M√°s All√° del Paper)

1. **RotatE (Sun et al., 2019):**
   - Relaciones como rotaciones en espacio complejo
   - Mejor para relaciones sim√©tricas

2. **ComplEx (Trouillon et al., 2016):**
   - Embeddings complejos
   - Maneja simetr√≠a/antisimetr√≠a

3. **ConvE (Dettmers et al., 2018):**
   - Convoluciones 2D
   - M√°s expresivo

4. **Encoder-based (Hwang et al.):**
   - GNN encoders para OOKB
   - Features de entidades

---

**Autor de la Implementaci√≥n:** Claude (Anthropic)  
**Basado en:** Bordes et al., "Translating Embeddings for Modeling Multi-relational Data", NIPS 2013  
**Fecha:** Febrero 2026
