#!/usr/bin/env python3
"""
GUÃA DE INICIO RÃPIDO - TransE Implementation

Este script muestra cÃ³mo usar la implementaciÃ³n de TransE paso a paso.
"""

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           TransE: Translating Embeddings for Multi-relational Data    â•‘
â•‘                    ImplementaciÃ³n Fiel al Paper Original              â•‘
â•‘                        (Bordes et al., 2013)                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("\nğŸ“š ARCHIVOS GENERADOS:\n")
print("1. transe_model.py          - ImplementaciÃ³n completa del modelo")
print("2. README_TransE.md         - DocumentaciÃ³n detallada")
print("3. run_experiments.py       - Configuraciones predefinidas")
print("4. NOTAS_TECNICAS.md        - AnÃ¡lisis tÃ©cnico y comparaciÃ³n")
print("5. inicio_rapido.py         - Este archivo")

print("\n" + "="*70)
print("OPCIÃ“N 1: EJECUCIÃ“N ESTÃNDAR")
print("="*70)

print("""
# Editar configuraciÃ³n en transe_model.py (funciÃ³n main):
DATASET_NAME = 'CoDEx-M'
MODE = 'standard'  # 'standard', 'ookb', o 'inductive'

# Ejecutar:
python transe_model.py
""")

print("="*70)
print("OPCIÃ“N 2: USAR CONFIGURACIONES PREDEFINIDAS")
print("="*70)

print("""
# Listar configuraciones disponibles:
python run_experiments.py list

# Ejecutar configuraciÃ³n especÃ­fica:
python run_experiments.py codex_standard   # Transductivo
python run_experiments.py codex_ookb       # Entidades nuevas
python run_experiments.py wordnet          # WordNet (paper)
python run_experiments.py freebase         # Freebase (paper)

# Estudio comparativo (3 escenarios):
python run_experiments.py comparative

# Estudio de ablation (impacto de hiperparÃ¡metros):
python run_experiments.py ablation
""")

print("="*70)
print("OPCIÃ“N 3: USO PROGRAMÃTICO")
print("="*70)

print("""
from transe_model import TransE, train_transe
from data_loader import KGDataLoader
from evaluator import UnifiedKGScorer
import torch

# 1. Cargar datos
loader = KGDataLoader('CoDEx-M', mode='standard')
loader.load()

# 2. Crear modelo
model = TransE(
    num_entities=loader.num_entities,
    num_relations=loader.num_relations,
    embedding_dim=50,
    norm_order=1,  # L1
    margin=1.0,
    device='cuda'
)

# 3. Entrenar
model, history = train_transe(
    model=model,
    train_data=loader.train_data,
    valid_data=loader.valid_data,
    num_entities=loader.num_entities,
    num_epochs=1000,
    batch_size=128,
    learning_rate=0.01
)

# 4. Evaluar
scorer = UnifiedKGScorer()

def predict_fn(h, r, t):
    model.eval()
    with torch.no_grad():
        return model.score_triples(h, r, t)

metrics = scorer.evaluate_ranking(
    predict_fn=predict_fn,
    test_triples=loader.test_data.cpu().numpy(),
    num_entities=loader.num_entities
)

# 5. Generar reporte
scorer.export_report("TransE", "reporte.pdf")
""")

print("="*70)
print("CONFIGURACIONES DEL PAPER")
print("="*70)

print("""
WordNet (WN):
  - embedding_dim: 20
  - learning_rate: 0.01
  - margin: 2.0
  - norm_order: 1 (L1)
  - Hits@10 esperado: ~89%

Freebase (FB15k):
  - embedding_dim: 50
  - learning_rate: 0.01
  - margin: 1.0
  - norm_order: 1 (L1)
  - Hits@10 esperado: ~47%

Large Scale (FB1M):
  - embedding_dim: 50
  - learning_rate: 0.01
  - margin: 1.0
  - norm_order: 2 (L2)
  - Hits@10 esperado: ~34%
""")

print("="*70)
print("ESTRUCTURA DE ARCHIVOS REQUERIDA")
print("="*70)

print("""
Su estructura de datos debe ser:

data/
â”œâ”€â”€ newlinks/              # Datasets transductivos
â”‚   â”œâ”€â”€ CoDEx-M/
â”‚   â”‚   â”œâ”€â”€ train.txt
â”‚   â”‚   â”œâ”€â”€ valid.txt
â”‚   â”‚   â””â”€â”€ test.txt
â”‚   â”œâ”€â”€ FB15k-237/
â”‚   â””â”€â”€ WN18RR/
â”‚
â”œâ”€â”€ newentities/           # Datasets OOKB
â”‚   â””â”€â”€ CoDEx-M/
â”‚       â”œâ”€â”€ train.txt      # Entidades conocidas
â”‚       â”œâ”€â”€ valid.txt
â”‚       â””â”€â”€ test.txt       # Incluye entidades nuevas
â”‚
â””â”€â”€ newlinks/              # Datasets inductivos
    â””â”€â”€ CoDEx-M/
        â””â”€â”€ NL-25/         # 25% relaciones nuevas
            â”œâ”€â”€ train.txt
            â”œâ”€â”€ valid.txt
            â””â”€â”€ test.txt

Formato de los archivos .txt (TSV):
head_entity<TAB>relation<TAB>tail_entity
Paris<TAB>capital_of<TAB>France
Einstein<TAB>born_in<TAB>Germany
""")

print("="*70)
print("SALIDAS GENERADAS")
print("="*70)

print("""
Al ejecutar, se generan:

1. Terminal output:
   - Progreso de entrenamiento (loss, MRR validation)
   - MÃ©tricas finales (MRR, Hits@K, AUC, F1)

2. Archivo PDF:
   TransE_<dataset>_<mode>_reporte.pdf
   
   Contenido:
   - PÃ¡gina 1: Resumen ejecutivo con mÃ©tricas
   - PÃ¡gina 2: Curvas ROC y Precision-Recall
   - PÃ¡gina 3: DistribuciÃ³n de scores (separabilidad)
   - PÃ¡gina 4: Histograma de ranks

3. Modelo entrenado:
   (Puede guardarse con torch.save si se desea)
""")

print("="*70)
print("MÃ‰TRICAS REPORTADAS")
print("="*70)

print("""
Ranking (Link Prediction):
  - MRR (Mean Reciprocal Rank): Promedio de 1/rank
  - MR (Mean Rank): Rank promedio de la entidad correcta
  - Hits@1: % de predicciones correctas en top-1
  - Hits@3: % de predicciones correctas en top-3
  - Hits@10: % de predicciones correctas en top-10

ClasificaciÃ³n (Triple Classification):
  - AUC-ROC: Ãrea bajo curva ROC
  - Accuracy: % de tripletas correctamente clasificadas
  - F1-Score: Media armÃ³nica de precision y recall
  - Precision: TP / (TP + FP)
  - Recall: TP / (TP + FN)
""")

print("="*70)
print("TROUBLESHOOTING")
print("="*70)

print("""
Problema: "FileNotFoundError: No se encontrÃ³ train.txt"
SoluciÃ³n: Verificar que la estructura de carpetas data/ sea correcta

Problema: "RuntimeError: CUDA out of memory"
SoluciÃ³n: Reducir batch_size o usar device='cpu'

Problema: "KeyError en entity2id"
SoluciÃ³n: En modo OOKB, esto es normal. El cÃ³digo lo maneja automÃ¡ticamente.

Problema: Rendimiento muy bajo en OOKB
SoluciÃ³n: Esto es esperado. TransE no fue diseÃ±ado para OOKB.
          El embedding especial es solo una baseline.

Problema: Loss no baja
SoluciÃ³n: 
  - Verificar que normalize_entity_embeddings() se llama
  - Probar diferentes learning rates (0.001, 0.01, 0.1)
  - Verificar que el margin no sea muy grande
""")

print("="*70)
print("PREGUNTAS FRECUENTES")
print("="*70)

print("""
Q: Â¿Por quÃ© usar -||h+r-t|| en lugar de ||h+r-t||?
A: El evaluador espera scores donde MAYOR es MEJOR.
   Distancia pequeÃ±a = buena predicciÃ³n â†’ score negativo alto.

Q: Â¿CuÃ¡ndo normalizar las entidades?
A: ANTES de cada Ã©poca (lÃ­nea 5 del Algoritmo 1).
   NO despuÃ©s del gradiente.

Q: Â¿Por quÃ© no normalizar las relaciones durante entrenamiento?
A: Solo se normalizan en inicializaciÃ³n (lÃ­nea 2).
   El paper NO las renormaliza despuÃ©s.

Q: Â¿QuÃ© hacer con entidades OOKB?
A: El cÃ³digo usa un embedding especial (unknown_entity_embedding).
   El rendimiento serÃ¡ bajo, como se espera.

Q: Â¿CÃ³mo se compara con mÃ©todos modernos en OOKB?
A: TransE serÃ¡ mucho peor que GNN-based encoders.
   Eso es el objetivo: establecer baseline para comparaciÃ³n.

Q: Â¿Puedo usar TransE para mi dataset?
A: SÃ­, solo necesitas archivos .txt con formato:
   head<TAB>relation<TAB>tail
""")

print("="*70)
print("LECTURAS RECOMENDADAS")
print("="*70)

print("""
1. Paper original:
   Bordes et al., "Translating Embeddings for Modeling Multi-relational Data"
   NIPS 2013

2. README_TransE.md
   ExplicaciÃ³n detallada de cada componente vs el paper

3. NOTAS_TECNICAS.md
   AnÃ¡lisis de diferencias, validaciÃ³n, y extensiones

4. Paper de comparaciÃ³n (OOKB):
   Hamaguchi et al., "Knowledge Transfer for Out-of-Knowledge-Base Entities"
   IJCAI 2017
""")

print("\n" + "="*70)
print("Â¡LISTO PARA EMPEZAR!")
print("="*70)
print("\nEjecutar uno de estos comandos:\n")
print("  python transe_model.py")
print("  python run_experiments.py codex_standard")
print("  python run_experiments.py list")
print("\n" + "="*70 + "\n")
